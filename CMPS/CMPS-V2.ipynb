{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7397ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import math, time\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b81a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_imgs(imgs, l1=4, l2=5, s1=6, s2=6, name=\"\"):\n",
    "    plt.rcParams['figure.figsize'] = (s1, s2)\n",
    "    imgs = imgs.cpu().reshape([-1, 28, 28])\n",
    "    g, ax = plt.subplots(l1, l2)\n",
    "    for i in range(l1):\n",
    "        for j in range(l2):\n",
    "            a = i * l2 + j\n",
    "            if (a >= imgs.shape[0]):\n",
    "                break\n",
    "            ax[i][j].imshow(imgs[a, :, :], cmap='gray')\n",
    "            ax[i][j].set_xticks([])\n",
    "            ax[i][j].set_yticks([])\n",
    "    if name != \"\":\n",
    "        plt.savefig(path + str(name) + \".png\")\n",
    "    #plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "def show_loss(train_loss_s, test_loss_s):\n",
    "    plt.rcParams['figure.figsize'] = (10, 10)\n",
    "    plt.plot(train_loss_s, \"o-\", label='train loss')\n",
    "    plt.plot(test_loss_s, \"o-\", label='test loss')\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend(loc=1)\n",
    "    plt.savefig(path + \"loss.png\")\n",
    "    plt.clf()\n",
    "\n",
    "def show_Acc(train_Acc_s, test_Acc_s):\n",
    "    plt.rcParams['figure.figsize'] = (10, 10)\n",
    "    plt.plot(train_Acc_s, \"o-\", label='train Acc')\n",
    "    plt.plot(test_Acc_s, \"o-\", label='test Acc')\n",
    "    plt.ylabel(\"Acc\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend(loc=1)\n",
    "    plt.savefig(path + \"Acc.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed8e05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMPS(nn.Module):\n",
    "    def __init__ (self, Dmax, n, c, mydevice=torch.device('cpu')):\n",
    "        super(CMPS,self).__init__()\n",
    "        self.Dmax = Dmax\n",
    "        self.n = n\n",
    "        self.c = c\n",
    "        self.bond_dims = [self.Dmax for i in range(n - 1)] + [1]\n",
    "        self.tensors = []\n",
    "        for i in range(self.n - 1):\n",
    "            t = torch.randn(self.bond_dims[i - 1], 2, self.bond_dims[i], device=mydevice)\n",
    "            t = Variable(t, requires_grad = True)\n",
    "            self.tensors.append(t)\n",
    "        t = torch.rand(self.bond_dims[self.n - 2], 2, self.bond_dims[self.n - 1], c, device=mydevice)\n",
    "        t = Variable(t, requires_grad = True)\n",
    "        self.tensors.append(t)\n",
    "        self.normalize()\n",
    "    \n",
    "    def getNorm(self):\n",
    "        result = torch.tensordot(self.tensors[0], self.tensors[0], dims=([1], [1]))\n",
    "        for i in range(1,self.n - 1):\n",
    "            result = torch.einsum(\"niol,ijk,ljm->nkom\", result, self.tensors[i],self.tensors[i])\n",
    "        result = torch.einsum(\"niol,ijkp,ljmp->nkomp\", result, self.tensors[self.n - 1], self.tensors[self.n - 1])\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def normalize(self):\n",
    "        result = torch.tensordot(self.tensors[0], self.tensors[0], dims=([1], [1]))\n",
    "        res_max = result.max()\n",
    "        tensor = self.tensors[0].detach()\n",
    "        tensor = tensor / torch.sqrt(res_max)\n",
    "        self.tensors[0] = Variable(tensor, requires_grad = True)\n",
    "        result /= res_max\n",
    "        for i in range(1,self.n - 1):\n",
    "            result = torch.einsum(\"niol,ijk,ljm->nkom\", result, self.tensors[i],self.tensors[i])\n",
    "            res_max = result.max()\n",
    "            tensor = self.tensors[i].detach()\n",
    "            tensor = tensor / torch.sqrt(res_max)\n",
    "            self.tensors[i] = Variable(tensor, requires_grad = True)\n",
    "            result /= res_max           \n",
    "        result = torch.einsum(\"niol,ijkp,ljmp->nkomp\", result, self.tensors[self.n - 1], self.tensors[self.n - 1])\n",
    "        tensor = self.tensors[self.n - 1].detach()\n",
    "        for i in range(self.c):\n",
    "            tensor[:,:,:,i] = tensor[:,:,:,i] / torch.sqrt(result[0,0,0,0,i])\n",
    "        self.tensors[self.n - 1] = Variable(tensor, requires_grad = True)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        result = torch.einsum(\"ijk,lmn,bj,bm->bkn\", self.tensors[0], self.tensors[0], x[:,0], x[:,0])\n",
    "        for i in range(1, 784-1):\n",
    "            result = torch.einsum(\"bil,ijk,lmn,bj,bm->bkn\",result, self.tensors[i], self.tensors[i], x[:,i], x[:,i])\n",
    "            result *= 2.5\n",
    "        result = torch.einsum(\"bil,ijkc,lmnc,bj,bm->bc\",result, self.tensors[-1], self.tensors[-1], x[:,-1], x[:,-1])\n",
    "        result = result/(self.getNorm().view(self.c))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3650232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_now():\n",
    "    return time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "\n",
    "def mapData2Spin(data):\n",
    "    newData = torch.tensor(\n",
    "        np.concatenate([\n",
    "            np.cos(np.pi / 2 * data).reshape(len(data), n, 1),\n",
    "            np.sin(np.pi / 2 * data).reshape(len(data), n, 1)\n",
    "        ],\n",
    "                       axis=2))\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ada6fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cmps,\n",
    "          SpinData_train,\n",
    "          train_label,\n",
    "          SpinData_test,\n",
    "          test_label,\n",
    "          batch_size,\n",
    "          epochs=5,\n",
    "          learning_rate=0.001,\n",
    "          mydevice=torch.device('cpu')):\n",
    "    train_loss_s = []\n",
    "    train_Acc_s = []\n",
    "    test_loss_s = []\n",
    "    test_Acc_s = []\n",
    "    n = cmps.n\n",
    "    start_time = time.time()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(cmps.tensors,lr=learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = []\n",
    "        train_Acc = []\n",
    "        test_loss = []\n",
    "        test_Acc = []\n",
    "        maxnum = 0\n",
    "        for batch_now in range(len(SpinData_train) // batch_size):\n",
    "            SpinDatas = SpinData_train[(batch_now) *batch_size:(batch_now + 1) * batch_size]\n",
    "            label = train_label[(batch_now) *batch_size:(batch_now + 1) * batch_size]\n",
    "            out = cmps(SpinDatas)\n",
    "            loss = criterion(out,label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cmps.normalize()\n",
    "            maxnum = max(maxnum,torch.max(out.data))\n",
    "            pred_label = torch.max(out.data, 1).indices\n",
    "            correct_cnt = (pred_label == label).sum()\n",
    "            train_loss.append(loss.data)\n",
    "            train_Acc.append(correct_cnt)\n",
    "        train_loss_s.append(np.mean(train_loss))\n",
    "        train_Acc_s.append(np.sum(train_Acc)/len(SpinData_train))\n",
    "        for batch_now in range(len(SpinData_test) // batch_size):\n",
    "            SpinDatas = SpinData_test[(batch_now) *batch_size:(batch_now + 1) * batch_size]\n",
    "            label = test_label[(batch_now) *batch_size:(batch_now + 1) * batch_size]\n",
    "            out = cmps(SpinDatas)\n",
    "            loss = criterion(out,label)\n",
    "            pred_label = torch.max(out.data, 1).indices\n",
    "            correct_cnt = (pred_label == label).sum()\n",
    "            test_loss.append(loss.data)\n",
    "            test_Acc.append(correct_cnt)\n",
    "        test_loss_s.append(np.mean(test_loss))\n",
    "        test_Acc_s.append(np.sum(test_Acc)/len(SpinData_test))\n",
    "        print(epoch + 1,train_loss_s[-1],train_Acc_s[-1],test_loss_s[-1],test_Acc_s[-1],maxnum,time.time()-start_time)\n",
    "        show_loss(train_loss_s, test_loss_s)\n",
    "        show_Acc(train_Acc_s, test_Acc_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16016e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220724_214907_1000_50_500_5_0.005\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "mydevice = torch.device('cpu')\n",
    "n = 784\n",
    "m = 1000\n",
    "tm = 500\n",
    "Dmax = 5\n",
    "c = 10\n",
    "batch_size = 50\n",
    "learning_rate = 0.005\n",
    "path = time_now() + \"_\" + str(m) + \"_\" + str(batch_size) + \"_\" + str(\n",
    "    tm) + \"_\" + str(Dmax) + \"_\" + str(learning_rate)\n",
    "print(path)\n",
    "os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecc43da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 784, 2])\n",
      "torch.Size([500, 784, 2])\n",
      "torch.Size([1000])\n",
      "torch.Size([1000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4500x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"./\" + path + \"/\"\n",
    "raw_data = np.load(\"data_bin.npz\")\n",
    "train_data = raw_data['train_data']\n",
    "train_data = torch.Tensor(train_data[:m, :])\n",
    "show_imgs(train_data, 5, 15, 15, 5, \"train_fig\")\n",
    "SpinData_train = mapData2Spin(train_data)\n",
    "print(SpinData_train.shape)\n",
    "test_data = raw_data['train_data']\n",
    "test_data = torch.Tensor(test_data[:tm, :])\n",
    "SpinData_test = mapData2Spin(test_data)\n",
    "print(SpinData_test.shape)\n",
    "train_label = torch.tensor(raw_data['train_label'][:m], dtype = torch.long)\n",
    "test_label = torch.tensor(raw_data['test_label'][:m], dtype = torch.long)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "SpinData_train = SpinData_train.to(mydevice)\n",
    "SpinData_test = SpinData_test.to(mydevice)\n",
    "\n",
    "cmps = CMPS(Dmax, n, c, mydevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37b4671a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5.400017113666363e+24 0.092 1.3937024997432444e+22 0.102 tensor(9.0501e+27) 28.32327675819397\n",
      "2 5.377613917886157e+24 0.092 1.3755582588963722e+22 0.102 tensor(9.0368e+27) 59.473910331726074\n",
      "3 5.355206870709274e+24 0.092 1.357416796033969e+22 0.102 tensor(9.0236e+27) 91.62163615226746\n",
      "4 5.332795353068174e+24 0.092 1.339278127097473e+22 0.102 tensor(9.0104e+27) 123.08135485649109\n",
      "5 5.310379376563772e+24 0.092 1.3211422680166227e+22 0.102 tensor(8.9971e+27) 151.09310936927795\n",
      "6 5.287958952796341e+24 0.092 1.3030092347118576e+22 0.102 tensor(8.9839e+27) 178.99333000183105\n",
      "7 5.265534093370896e+24 0.092 1.2848790430940209e+22 0.102 tensor(8.9707e+27) 206.9028639793396\n",
      "8 5.243104809890814e+24 0.092 1.266751709062411e+22 0.102 tensor(8.9575e+27) 235.43025088310242\n",
      "9 5.220671113961638e+24 0.092 1.2486272485073564e+22 0.102 tensor(8.9443e+27) 273.92173171043396\n",
      "10 5.198233017191393e+24 0.092 1.2305056773082362e+22 0.102 tensor(8.9311e+27) 310.42026138305664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x3000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train(cmps,SpinData_train,train_label,SpinData_test,test_label,batch_size,epochs = 2,learning_rate = 1e-3)\n",
    "train(cmps,SpinData_train,train_label,SpinData_test,test_label,batch_size,epochs = 10,learning_rate = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb9b755",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
