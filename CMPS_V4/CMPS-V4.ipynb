{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7397ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "import math, time\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39b81a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_imgs(imgs, l1=4, l2=5, s1=6, s2=6, name=\"\"):\n",
    "    plt.rcParams['figure.figsize'] = (s1, s2)\n",
    "    imgs = imgs.cpu().reshape([-1, 28, 28])\n",
    "    g, ax = plt.subplots(l1, l2)\n",
    "    for i in range(l1):\n",
    "        for j in range(l2):\n",
    "            a = i * l2 + j\n",
    "            if (a >= imgs.shape[0]):\n",
    "                break\n",
    "            ax[i][j].imshow(imgs[a, :, :], cmap='gray')\n",
    "            ax[i][j].set_xticks([])\n",
    "            ax[i][j].set_yticks([])\n",
    "    if name != \"\":\n",
    "        plt.savefig(path + str(name) + \".png\")\n",
    "    #plt.show()\n",
    "    plt.clf()\n",
    "\n",
    "def show_loss(train_loss_s, test_loss_s):\n",
    "    plt.rcParams['figure.figsize'] = (10, 10)\n",
    "    plt.plot(train_loss_s, \"o-\", label='train loss')\n",
    "    plt.plot(test_loss_s, \"o-\", label='test loss')\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend(loc=1)\n",
    "    plt.savefig(path + \"loss.png\")\n",
    "    plt.clf()\n",
    "\n",
    "def show_Acc(train_Acc_s, test_Acc_s):\n",
    "    plt.rcParams['figure.figsize'] = (10, 10)\n",
    "    plt.plot(train_Acc_s, \"o-\", label='train Acc')\n",
    "    plt.plot(test_Acc_s, \"o-\", label='test Acc')\n",
    "    plt.ylabel(\"Acc\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.legend(loc=1)\n",
    "    plt.savefig(path + \"Acc.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ed8e05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CMPS(nn.Module):\n",
    "    def __init__ (self, Dmax, n, c, mydevice=torch.device('cpu')):\n",
    "        super(CMPS,self).__init__()\n",
    "        self.Dmax = Dmax\n",
    "        self.n = n\n",
    "        self.c = c\n",
    "        self.bond_dims = [self.Dmax for i in range(n - 1)] + [1]\n",
    "        self.tensors = []\n",
    "        for i in range(self.n - 1):\n",
    "            t = torch.randn(self.bond_dims[i - 1], 2, self.bond_dims[i], device=mydevice)\n",
    "            t = Variable(t, requires_grad = True)\n",
    "            self.tensors.append(t)\n",
    "        t = torch.rand(self.bond_dims[self.n - 2], 2, self.bond_dims[self.n - 1], c, device=mydevice)\n",
    "        t = Variable(t, requires_grad = True)\n",
    "        self.tensors.append(t)\n",
    "        self.normalize()\n",
    "    \n",
    "    def getNorm(self):\n",
    "        result = torch.tensordot(self.tensors[0], self.tensors[0], dims=([1], [1]))\n",
    "        for i in range(1,self.n - 1):\n",
    "            result = torch.einsum(\"niol,ijk,ljm->nkom\", result, self.tensors[i],self.tensors[i])\n",
    "        result = torch.einsum(\"niol,ijkp,ljmp->nkomp\", result, self.tensors[self.n - 1], self.tensors[self.n - 1])\n",
    "        return result\n",
    "    \n",
    "    \n",
    "    def normalize(self):\n",
    "        result = torch.tensordot(self.tensors[0], self.tensors[0], dims=([1], [1]))\n",
    "        res_max = result.max()\n",
    "        tensor = self.tensors[0].detach()\n",
    "        tensor = tensor / torch.sqrt(res_max)\n",
    "        self.tensors[0] = Variable(tensor, requires_grad = True)\n",
    "        result /= res_max\n",
    "        for i in range(1,self.n - 1):\n",
    "            result = torch.einsum(\"niol,ijk,ljm->nkom\", result, self.tensors[i],self.tensors[i])\n",
    "            res_max = result.max()\n",
    "            tensor = self.tensors[i].detach()\n",
    "            tensor = tensor / torch.sqrt(res_max)\n",
    "            self.tensors[i] = Variable(tensor, requires_grad = True)\n",
    "            result /= res_max           \n",
    "        result = torch.einsum(\"niol,ijkp,ljmp->nkomp\", result, self.tensors[self.n - 1], self.tensors[self.n - 1])\n",
    "        tensor = self.tensors[self.n - 1].detach()\n",
    "        for i in range(self.c):\n",
    "            tensor[:,:,:,i] = tensor[:,:,:,i] / torch.sqrt(result[0,0,0,0,i])\n",
    "        self.tensors[self.n - 1] = Variable(tensor, requires_grad = True)\n",
    "    \n",
    "    def forward(self,x,label):\n",
    "        result = torch.einsum(\"ijk,bj->bk\", self.tensors[0], x[:,0])\n",
    "        for i in range(1, 784-1):\n",
    "            result = torch.einsum(\"bi,ijk,bj->bk\",result, self.tensors[i], x[:,i])\n",
    "        result = torch.einsum(\"bi,ijkc,bj,bc->b\",result, self.tensors[-1], x[:,-1],label)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3650232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_now():\n",
    "    return time.strftime(\"%Y%m%d_%H%M%S\", time.localtime())\n",
    "\n",
    "def mapData2Spin(data):\n",
    "    newData = torch.tensor(\n",
    "        np.concatenate([\n",
    "            np.cos(np.pi / 2 * data).reshape(len(data), n, 1),\n",
    "            np.sin(np.pi / 2 * data).reshape(len(data), n, 1)\n",
    "        ],\n",
    "                       axis=2))\n",
    "    return newData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ada6fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cmps,\n",
    "          SpinData_train,\n",
    "          train_label,\n",
    "          SpinData_test,\n",
    "          test_label,\n",
    "          batch_size,\n",
    "          epochs=5,\n",
    "          learning_rate=0.001,\n",
    "          mydevice=torch.device('cpu')):\n",
    "    train_loss_s = []\n",
    "    train_Acc_s = []\n",
    "    test_loss_s = []\n",
    "    test_Acc_s = []\n",
    "    n = cmps.n\n",
    "    start_time = time.time()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(cmps.tensors,lr=learning_rate)\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = []\n",
    "        train_Acc = []\n",
    "        test_loss = []\n",
    "        test_Acc = []\n",
    "        maxnum = 0\n",
    "        for batch_now in range(len(SpinData_train) // batch_size):\n",
    "            SpinDatas = SpinData_train[(batch_now) *batch_size:(batch_now + 1) * batch_size]\n",
    "            label = train_label[(batch_now) *batch_size:(batch_now + 1) * batch_size]\n",
    "            out = cmps(SpinDatas,label)\n",
    "            #print(out)\n",
    "            loss = -2*torch.mean(torch.log(torch.abs(out)))\n",
    "            #print(out)\n",
    "            #print(torch.log(torch.abs(out)))\n",
    "            #print(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            cmps.normalize()\n",
    "            maxnum = max(maxnum,torch.max(out.data))\n",
    "            #pred_label = torch.max(out.data, 1).indices\n",
    "            #correct_cnt = (pred_label == label).sum()\n",
    "            train_loss.append(loss.data)\n",
    "            #train_Acc.append(correct_cnt)\n",
    "        train_loss_s.append(np.mean(train_loss))\n",
    "        train_Acc_s.append(np.sum(train_Acc)/len(SpinData_train))\n",
    "        for batch_now in range(len(SpinData_test) // batch_size):\n",
    "            SpinDatas = SpinData_test[(batch_now) *batch_size:(batch_now + 1) * batch_size]\n",
    "            label = test_label[(batch_now) *batch_size:(batch_now + 1) * batch_size]\n",
    "            out = cmps(SpinDatas,label)\n",
    "            loss = -2*torch.mean(torch.log(torch.abs(out)))\n",
    "            #pred_label = torch.max(out.data, 1).indices\n",
    "            #correct_cnt = (pred_label == label).sum()\n",
    "            test_loss.append(loss.data)\n",
    "            #test_Acc.append(correct_cnt)\n",
    "        test_loss_s.append(np.mean(test_loss))\n",
    "        test_Acc_s.append(np.sum(test_Acc)/len(SpinData_test))\n",
    "        print(epoch + 1,train_loss_s[-1],train_Acc_s[-1],test_loss_s[-1],test_Acc_s[-1],maxnum,time.time()-start_time)\n",
    "        show_loss(train_loss_s, test_loss_s)\n",
    "        show_Acc(train_Acc_s, test_Acc_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16016e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20220724_234024_60000_10000_10000_10_0.005\n"
     ]
    }
   ],
   "source": [
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "mydevice = torch.device('cpu')\n",
    "n = 784\n",
    "m = 60000\n",
    "tm = 10000\n",
    "Dmax = 10\n",
    "c = 10\n",
    "batch_size = 10000\n",
    "learning_rate = 0.005\n",
    "path = time_now() + \"_\" + str(m) + \"_\" + str(batch_size) + \"_\" + str(\n",
    "    tm) + \"_\" + str(Dmax) + \"_\" + str(learning_rate)\n",
    "print(path)\n",
    "os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecc43da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 784, 2])\n",
      "torch.Size([10000, 784, 2])\n",
      "torch.Size([60000, 10])\n",
      "torch.Size([10000, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 4500x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = \"./\" + path + \"/\"\n",
    "raw_data = np.load(\"data_bin.npz\")\n",
    "train_data = raw_data['train_data']\n",
    "train_data = torch.Tensor(train_data[:m, :])\n",
    "show_imgs(train_data, 5, 15, 15, 5, \"train_fig\")\n",
    "SpinData_train = mapData2Spin(train_data)\n",
    "print(SpinData_train.shape)\n",
    "test_data = raw_data['train_data']\n",
    "test_data = torch.Tensor(test_data[:tm, :])\n",
    "SpinData_test = mapData2Spin(test_data)\n",
    "print(SpinData_test.shape)\n",
    "train_label = raw_data['train_label'][:m]\n",
    "train_label = np.eye(c)[train_label]\n",
    "train_label = torch.Tensor(train_label)\n",
    "test_label = raw_data['test_label'][:m]\n",
    "test_label = np.eye(c)[test_label]\n",
    "test_label = torch.Tensor(test_label)\n",
    "print(train_label.shape)\n",
    "print(test_label.shape)\n",
    "torch.manual_seed(1)\n",
    "np.random.seed(1)\n",
    "SpinData_train = SpinData_train.to(mydevice)\n",
    "SpinData_test = SpinData_test.to(mydevice)\n",
    "\n",
    "cmps = CMPS(Dmax, n, c, mydevice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37b4671a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 514.1412229624588 0.0 494.3837938948187 0.0 tensor(1.3109e-99) 14.589141607284546\n",
      "2 493.9373686663661 0.0 493.33029501119034 0.0 tensor(1.9704e-99) 31.76314640045166\n",
      "3 493.1309675310192 0.0 492.768547823417 0.0 tensor(2.5560e-99) 55.26916980743408\n",
      "4 492.6693832737619 0.0 492.42375134656373 0.0 tensor(3.0115e-99) 74.94097971916199\n",
      "5 492.38000260523177 0.0 492.20196819854107 0.0 tensor(3.3529e-99) 95.35163402557373\n",
      "6 492.193125562249 0.0 492.0575995647587 0.0 tensor(3.6021e-99) 115.58974885940552\n",
      "7 492.07104525172014 0.0 491.96331517315934 0.0 tensor(3.7809e-99) 131.67711758613586\n",
      "8 491.9910321491236 0.0 491.90098750106563 0.0 tensor(3.9080e-99) 151.4003245830536\n",
      "9 491.9386196266396 0.0 491.8602296740993 0.0 tensor(3.9979e-99) 167.0203239917755\n",
      "10 491.9043914282334 0.0 491.8336759768667 0.0 tensor(4.0615e-99) 182.52707719802856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 3000x3000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#train(cmps,SpinData_train,train_label,SpinData_test,test_label,batch_size,epochs = 2,learning_rate = 1e-3)\n",
    "train(cmps,SpinData_train,train_label,SpinData_test,test_label,batch_size,epochs = 10,learning_rate = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feb9b755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb31624c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
